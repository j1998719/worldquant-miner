"""
Alpha Miner - ä¸»å¾ªç¯
åè°ƒæ‰€æœ‰ Agents å®ç°è¿­ä»£ä¼˜åŒ–
"""
import logging
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

from core.wq_api import WorldQuantAPI, SimulationSettings, AlphaResult
from core.data_loader import DataLoader
from agents.hypothesis_agent import HypothesisAgent
from agents.alpha_designer_agent import AlphaDesignerAgent
from agents.evaluator_agent import EvaluatorAgent
from utils.config_loader import ConfigLoader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  # ä½¿ç”¨ INFO çº§åˆ«ï¼ˆå¦‚éœ€è°ƒè¯•å¯æ”¹ä¸º DEBUGï¼‰
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('alpha_miner.log')
    ]
)
logger = logging.getLogger(__name__)


class AlphaMiner:
    """
    Alpha Miner ä¸»ç±»
    å®ç°è¿­ä»£ä¼˜åŒ–å¾ªç¯ï¼šç”Ÿæˆå‡è®¾ -> è®¾è®¡è¡¨è¾¾å¼ -> æ¨¡æ‹Ÿ -> è¯„ä¼° -> ä¼˜åŒ–/é‡æ–°ç”Ÿæˆ
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ– Alpha Miner
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œå¦‚æœä¸º None åˆ™ä» config.yaml åŠ è½½
        """
        if config is None:
            config = ConfigLoader.all()
        
        self.config = config
        
        # åˆå§‹åŒ– WQ API
        self.wq_api = WorldQuantAPI(
            username=config['worldquant_account'],
            password=config['worldquant_password']
        )
        
        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self.data_loader = DataLoader(
            enabled_datasets=config.get('enabled_field_datasets', [])
        )
        
        # åŠ è½½ operators å’Œ fieldsï¼ˆå®Œæ•´æ•°æ®ï¼‰
        logger.info("Loading operators and fields...")
        self.operators_data = self.data_loader.load_operators()  # å®Œæ•´çš„ operators.json æ•°æ®
        self.fields_data = self.data_loader.load_fields()  # æ ¹æ® enabled_field_datasets åŠ è½½çš„å®Œæ•´ fields æ•°æ®
        self.enabled_datasets = config.get('enabled_field_datasets', [])
        
        logger.info(f"ğŸ“š Loaded {len(self.operators_data)} operators")
        logger.info(f"ğŸ“š Loaded {len(self.fields_data)} fields from datasets: {', '.join(self.enabled_datasets)}")
        
        # åˆå§‹åŒ– Agents
        ollama_config = {
            'ollama_url': config.get('ollama_url', 'http://localhost:11434'),
            'ollama_model': config.get('ollama_model', 'gemma3:1b'),
            'temperature': 0.2
        }
        
        self.hypothesis_agent = HypothesisAgent(**ollama_config)
        self.designer_agent = AlphaDesignerAgent(**ollama_config)
        self.evaluator_agent = EvaluatorAgent(**ollama_config)
        
        # ç»“æœç›®å½•
        self.results_dir = Path("results")
        self.results_dir.mkdir(exist_ok=True)
        
        # æ–‡ä»¶è·¯å¾„ï¼ˆéƒ½åœ¨ results/ ä¸‹ï¼‰
        self.hypothesis_file = self.results_dir / "hypothesis.json"
        self.history_file = self.results_dir / "history.json"
        self.hopeful_alphas_file = self.results_dir / "hopeful_alphas.json"
        
        # æ¨¡æ‹Ÿè®¾ç½®
        self.sim_settings = SimulationSettings(
            region=config.get('worldquant_region', 'USA'),
            universe=config.get('worldquant_universe', 'TOP3000'),
            delay=1,
            neutralization="SUBINDUSTRY",
            truncation=0.08
        )
        
        # æˆåŠŸæ ‡å‡†ï¼ˆWorldQuant Brain's criteria - for reference onlyï¼‰
        self.success_criteria = {
            'min_sharpe': config.get('min_sharpe', 1.25),
            'min_fitness': config.get('min_fitness', 1.0),
            'max_turnover': config.get('max_turnover', 0.7),
            'min_turnover': config.get('min_turnover', 0.01),
            'min_returns': config.get('min_returns', 0.0)
        }
        
        # å†å²è®°å½•
        self.history = []
        self.all_hypotheses = []  # æ‰€æœ‰ç”Ÿæˆè¿‡çš„ hypothesis
        self.all_expressions = []  # æ‰€æœ‰å°è¯•è¿‡çš„ expressionï¼ˆé˜²é‡å¤ï¼‰
        
        # åŠ è½½å·²æœ‰çš„å†å²è®°å½•ï¼ˆé˜²é‡å¤ï¼‰
        self._load_existing_history()
    
    def _validate_recommendations(self, data: Dict, data_type: str = "hypothesis") -> Dict[str, Any]:
        """
        Rule-based éªŒè¯ recommended_fields å’Œ recommended_operators
        
        Args:
            data: hypothesis æˆ– analysis å­—å…¸
            data_type: "hypothesis" æˆ– "analysis"
        
        Returns:
            {
                'valid': bool,
                'reason': str (if invalid),
                'invalid_fields': List[str],
                'invalid_operators': List[str]
            }
        """
        # ä»å®Œæ•´æ•°æ®ä¸­æå– field IDs å’Œ operator names
        available_fields = set(f.get('id', f.get('name', '')) for f in self.fields_data)
        available_operators = set(op.get('name', '') for op in self.operators_data)
        
        recommended_fields = data.get('recommended_fields', [])
        recommended_operators = data.get('recommended_operators', [])
        
        # æ£€æŸ¥ fields
        invalid_fields = [f for f in recommended_fields if f not in available_fields]
        
        # æ£€æŸ¥ operators
        invalid_operators = [op for op in recommended_operators if op not in available_operators]
        
        if invalid_fields or invalid_operators:
            reason = []
            if invalid_fields:
                reason.append(f"{len(invalid_fields)}/{len(recommended_fields)} fields not found")
            if invalid_operators:
                reason.append(f"{len(invalid_operators)}/{len(recommended_operators)} operators not found")
            
            return {
                'valid': False,
                'reason': ', '.join(reason),
                'invalid_fields': invalid_fields,
                'invalid_operators': invalid_operators
            }
        
        return {'valid': True}
    
    def _validate_hypothesis(self, hypothesis: Dict) -> Dict[str, Any]:
        """
        éªŒè¯ hypothesisï¼ˆä½¿ç”¨é€šç”¨éªŒè¯æ–¹æ³•ï¼‰
        """
        return self._validate_recommendations(hypothesis, "hypothesis")
    
    def _validate_analysis(self, analysis: Dict) -> Dict[str, Any]:
        """
        éªŒè¯ evaluator ç”Ÿæˆçš„ analysisï¼ˆä½¿ç”¨é€šç”¨éªŒè¯æ–¹æ³•ï¼‰
        """
        return self._validate_recommendations(analysis, "analysis")
    
    def _load_existing_history(self):
        """
        ä» history.json å’Œ hypothesis.json åŠ è½½å·²æœ‰æ•°æ®ï¼ˆé˜²é‡å¤ï¼‰
        """
        # åŠ è½½ history.json
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    existing_history = json.load(f)
                
                # åŠ è½½åˆ° self.historyï¼ˆç”¨äºç»§ç»­ iteration è®¡æ•°ï¼‰
                self.history = existing_history
                
                # æå–æ‰€æœ‰å·²å°è¯•è¿‡çš„ expressions
                for record in existing_history:
                    expr = record.get('expression')
                    if expr and expr not in self.all_expressions:
                        self.all_expressions.append(expr)
                
                logger.info(f"ğŸ“‹ Loaded {len(existing_history)} history records, {len(self.all_expressions)} unique expressions")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load history.json: {e}")
        
        # åŠ è½½ hypothesis.json
        if self.hypothesis_file.exists():
            try:
                with open(self.hypothesis_file, 'r', encoding='utf-8') as f:
                    existing_hypotheses = json.load(f)
                
                self.all_hypotheses = existing_hypotheses
                logger.info(f"ğŸ“‹ Loaded {len(existing_hypotheses)} existing hypotheses")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load hypothesis.json: {e}")
    
    def run(self, max_iterations: int = 100):
        """
        è¿è¡Œä¸»å¾ªç¯ï¼šä¸æ–­ç”Ÿæˆå’Œæµ‹è¯• alphas
        
        Rule-based ç­–ç•¥ï¼š
        - Sharpe > 1.0 â†’ åŠ å…¥ hopeful_alphas.jsonï¼Œç»§ç»­æœç´¢
        - Sharpe < -1.0 â†’ åè½¬ååŠ å…¥ hopeful_alphas.jsonï¼Œç»§ç»­æœç´¢
        - abs(Sharpe) < 1.0 â†’ æ”¾å¼ƒï¼Œç”Ÿæˆæ–°å‡è®¾
        
        Args:
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        logger.info("=" * 80)
        logger.info("ğŸš€ Alpha Miner Started (Rule-based Strategy)")
        logger.info("=" * 80)
        logger.info("ğŸ“‹ Decision Rules:")
        logger.info("   âœ… Sharpe > 1.0  â†’ Add to hopeful_alphas.json")
        logger.info("   ğŸ”„ Sharpe < -1.0 â†’ Reverse & add to hopeful_alphas.json")
        logger.info("   âŒ |Sharpe| < 1.0 â†’ Abandon, generate new hypothesis")
        logger.info("")
        logger.info(f"ğŸ¯ WorldQuant Success Criteria (for reference):")
        logger.info(f"   Sharpe >= {self.success_criteria['min_sharpe']}")
        logger.info(f"   Fitness >= {self.success_criteria['min_fitness']}")
        logger.info(f"   {self.success_criteria['min_turnover']} <= Turnover <= {self.success_criteria['max_turnover']}")
        logger.info("=" * 80)
        
        # ä»ç°æœ‰ history ç»§ç»­ï¼ˆå¦‚æœæœ‰ï¼‰
        iteration = len(self.history)
        current_hypothesis = None
        current_expression = None
        previous_failures = []
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"\n{'=' * 80}")
            logger.info(f"ğŸ“ Iteration {iteration}/{max_iterations}")
            logger.info(f"{'=' * 80}")
            
            try:
                # æ”¶é›†ä¹‹å‰å°è¯•è¿‡çš„ expressionsï¼ˆç”¨äºé¿å…é‡å¤ï¼‰
                previous_expressions = [h['expression'] for h in self.history if 'expression' in h]
                
                # Step 1: ç”Ÿæˆæˆ–ä½¿ç”¨ç°æœ‰å‡è®¾
                if current_hypothesis is None:
                    logger.info("\nğŸ§  Step 1: Generating Hypothesis...")
                    
                    hypothesis_result = self.hypothesis_agent.execute({
                        'previous_failures': previous_failures,
                        'operators_data': self.operators_data,
                        'fields_data': self.fields_data,
                        'enabled_datasets': self.enabled_datasets
                    })
                    
                    if not hypothesis_result['success']:
                        logger.error(f"Hypothesis generation failed: {hypothesis_result['error']}")
                        continue
                    
                    current_hypothesis = hypothesis_result['hypothesis']
                    logger.info(f"âœ… Hypothesis: {current_hypothesis['hypothesis']}")
                    
                    # Rule-based éªŒè¯ï¼šæ£€æŸ¥ recommended fields å’Œ operators æ˜¯å¦çœŸå®å­˜åœ¨
                    validation_result = self._validate_hypothesis(current_hypothesis)
                    if not validation_result['valid']:
                        logger.warning(f"âš ï¸ Hypothesis validation failed: {validation_result['reason']}")
                        logger.warning(f"   Invalid fields: {validation_result.get('invalid_fields', [])}")
                        logger.warning(f"   Invalid operators: {validation_result.get('invalid_operators', [])}")
                        logger.warning("   Regenerating hypothesis...")
                        current_hypothesis = None
                        continue
                    
                    # ä¿å­˜ hypothesis
                    self.save_hypothesis(current_hypothesis)
                
                # Step 2: è®¾è®¡ Alpha è¡¨è¾¾å¼
                logger.info("\nğŸ¨ Step 2: Designing Alpha Expression...")
                
                design_result = self.designer_agent.execute({
                    'hypothesis': current_hypothesis,
                    'previous_attempts': self.all_expressions[-20:],
                    'operators_data': self.operators_data,
                    'fields_data': self.fields_data,
                    'enabled_datasets': self.enabled_datasets
                })
                
                if not design_result['success']:
                    logger.error(f"Alpha design failed: {design_result['error']}")
                    current_hypothesis = None
                    continue
                
                alpha_design = design_result['alpha_design']
                current_expression = alpha_design['expression']
                
                # æ£€æŸ¥é‡å¤
                if current_expression in self.all_expressions:
                    logger.warning(f"âš ï¸ Expression already tried: {current_expression}")
                    logger.warning("   Generating new hypothesis...")
                    current_hypothesis = None
                    current_expression = None
                    continue
                
                self.all_expressions.append(current_expression)
                logger.info(f"âœ… Expression: {current_expression} (unique)")
                
                # éªŒè¯è¡¨è¾¾å¼
                validation = self.data_loader.validate_expression(current_expression)
                if not validation['valid']:
                    logger.warning(f"âš ï¸ Invalid expression:")
                    logger.warning(f"  Unknown operators: {validation['unknown_operators']}")
                    logger.warning(f"  Unknown fields: {validation['unknown_fields']}")
                    # ç»§ç»­æ‰§è¡Œï¼Œè®© WQ API è¿”å›å…·ä½“é”™è¯¯
                
                # Step 3: æäº¤æ¨¡æ‹Ÿ
                logger.info("\nâš™ï¸ Step 3: Submitting Simulation...")
                result = self.wq_api.simulate_alpha(current_expression, self.sim_settings)
                
                if result is None:
                    logger.error("âŒ Simulation failed to submit")
                    # æ”¾å¼ƒå½“å‰ hypothesisï¼Œç”Ÿæˆæ–°çš„
                    current_hypothesis = None
                    current_expression = None
                    previous_failures.append(current_expression if current_expression else "simulation_failed")
                    continue
                
                # æ˜¾ç¤ºç»“æœ
                logger.info(f"\nğŸ“Š Results:")
                logger.info(f"  Sharpe:   {result.sharpe:.3f}")
                logger.info(f"  Fitness:  {result.fitness:.3f}")
                logger.info(f"  Turnover: {result.turnover:.3f}")
                logger.info(f"  Returns:  {result.returns:.3f}")
                
                # é¢„åˆ¤å†³ç­–
                if result.sharpe > 1.0:
                    logger.info(f"  âœ… Sharpe > 1.0 â†’ Will add to hopeful!")
                elif result.sharpe < -1.0:
                    logger.info(f"  ğŸ”„ Sharpe < -1.0 â†’ Will reverse & add to hopeful!")
                else:
                    logger.info(f"  âŒ |Sharpe| < 1.0 â†’ Will abandon")
                
                # Step 4: Rule-based å†³ç­–
                logger.info("\nğŸ“ˆ Step 4: Rule-based Decision...")
                
                sharpe = result.sharpe
                
                # ä¿å­˜å½“å‰çš„ hypothesis å’Œ expressionï¼ˆç”¨äºè®°å½• historyï¼‰
                record_hypothesis = current_hypothesis
                record_expression = current_expression
                
                # Rule 1: Sharpe > 1.0 â†’ Hopeful alpha!
                if sharpe > 1.0:
                    logger.info("âœ… HOPEFUL! Sharpe > 1.0")
                    logger.info("   Analyzing alpha...")
                    
                    # è°ƒç”¨ Evaluator ç”Ÿæˆåˆ†æ
                    eval_result = self.evaluator_agent.execute({
                        'expression': current_expression,
                        'result': result,
                        'hypothesis': current_hypothesis,
                        'operators_data': self.operators_data,
                        'fields_data': self.fields_data,
                        'enabled_datasets': self.enabled_datasets
                    })
                    
                    if eval_result['success']:
                        analysis = eval_result['analysis']
                        
                        # Rule-based éªŒè¯ analysis çš„ recommended fields å’Œ operators
                        validation_result = self._validate_analysis(analysis)
                        if not validation_result['valid']:
                            logger.warning(f"âš ï¸ Analysis validation failed: {validation_result['reason']}")
                            logger.warning(f"   Invalid fields: {validation_result.get('invalid_fields', [])}")
                            logger.warning(f"   Invalid operators: {validation_result.get('invalid_operators', [])}")
                            logger.warning("   Saving without invalid recommendations...")
                            # ç§»é™¤æ— æ•ˆçš„ recommendationsï¼ˆä»å®Œæ•´æ•°æ®ä¸­æå–ï¼‰
                            valid_fields = set(f.get('id', f.get('name', '')) for f in self.fields_data)
                            valid_operators = set(op.get('name', '') for op in self.operators_data)
                            analysis['recommended_fields'] = [f for f in analysis.get('recommended_fields', []) 
                                                             if f in valid_fields]
                            analysis['recommended_operators'] = [op for op in analysis.get('recommended_operators', []) 
                                                                if op in valid_operators]
                        
                        self.add_to_hopeful_alphas(current_expression, result, analysis)
                    
                    # ç»§ç»­æœç´¢æ›´å¥½çš„ alpha
                    current_hypothesis = None
                    current_expression = None
                
                # Rule 2: Sharpe < -1.0 â†’ Reverse and add to hopeful!
                elif sharpe < -1.0:
                    logger.info(f"ğŸ”„ REVERSE! Sharpe={sharpe:.3f} < -1.0")
                    logger.info(f"   Multiplying by -1 would give Sharpeâ‰ˆ{-sharpe:.3f}")
                    
                    reversed_expression = f"(-1 * ({current_expression}))"
                    logger.info(f"   Reversed: {reversed_expression}")
                    
                    # è°ƒç”¨ Evaluator ç”Ÿæˆåˆ†æï¼ˆä½¿ç”¨åè½¬åçš„ Sharpeï¼‰
                    eval_result = self.evaluator_agent.execute({
                        'expression': reversed_expression,
                        'result': result,
                        'hypothesis': current_hypothesis,
                        'operators_data': self.operators_data,
                        'fields_data': self.fields_data,
                        'enabled_datasets': self.enabled_datasets
                    })
                    
                    if eval_result['success']:
                        analysis = eval_result['analysis']
                        
                        # Rule-based éªŒè¯ analysis çš„ recommended fields å’Œ operators
                        validation_result = self._validate_analysis(analysis)
                        if not validation_result['valid']:
                            logger.warning(f"âš ï¸ Analysis validation failed: {validation_result['reason']}")
                            logger.warning(f"   Invalid fields: {validation_result.get('invalid_fields', [])}")
                            logger.warning(f"   Invalid operators: {validation_result.get('invalid_operators', [])}")
                            logger.warning("   Saving without invalid recommendations...")
                            # ç§»é™¤æ— æ•ˆçš„ recommendationsï¼ˆä»å®Œæ•´æ•°æ®ä¸­æå–ï¼‰
                            valid_fields = set(f.get('id', f.get('name', '')) for f in self.fields_data)
                            valid_operators = set(op.get('name', '') for op in self.operators_data)
                            analysis['recommended_fields'] = [f for f in analysis.get('recommended_fields', []) 
                                                             if f in valid_fields]
                            analysis['recommended_operators'] = [op for op in analysis.get('recommended_operators', []) 
                                                                if op in valid_operators]
                        
                        # åˆ›å»ºåè½¬åçš„è™šæ‹Ÿ result
                        reversed_result_data = AlphaResult(
                            alpha_id=result.alpha_id,
                            expression=reversed_expression,
                            sharpe=-result.sharpe,
                            fitness=-result.fitness,  # fitness é€šå¸¸ä¹Ÿä¼šåè½¬
                            turnover=result.turnover,
                            returns=-result.returns,
                            drawdown=result.drawdown,
                            margin=result.margin,
                            longCount=result.shortCount,
                            shortCount=result.longCount,
                            success=True
                        )
                        self.add_to_hopeful_alphas(reversed_expression, reversed_result_data, analysis)
                    
                    # ç»§ç»­æœç´¢
                    current_hypothesis = None
                    current_expression = None
                
                # Rule 3: abs(Sharpe) < 1.0 â†’ Abandon, try new hypothesis
                else:
                    logger.info(f"âŒ ABANDON! abs(Sharpe)={abs(sharpe):.3f} < 1.0")
                    logger.info("   Generating new hypothesis...")
                    
                    # æ”¾å¼ƒï¼Œç”Ÿæˆæ–°å‡è®¾
                    previous_failures.append(record_hypothesis['hypothesis'] if record_hypothesis else record_expression)
                    current_hypothesis = None
                    current_expression = None
                
                # è®°å½•å†å²ï¼ˆè¯¦ç»†è®°å½•ï¼‰
                self.history.append({
                    'iteration': iteration,
                    'hypothesis': record_hypothesis,  # åŒ…å« recommended_operators, fields, params
                    'expression': record_expression,
                    'result': {
                        'sharpe': result.sharpe,
                        'fitness': result.fitness,
                        'turnover': result.turnover,
                        'returns': result.returns,
                        'alpha_id': result.alpha_id,
                        'success': result.success,
                        'error_message': result.error_message
                    },
                    'decision': 'HOPEFUL' if sharpe > 1.0 else ('REVERSE' if sharpe < -1.0 else 'ABANDON'),
                    'timestamp': datetime.now().isoformat()
                })
                
                # å®æ—¶ä¿å­˜ history
                self.save_history()
            
            except KeyboardInterrupt:
                logger.info("\nâš ï¸ Interrupted by user")
                self.save_history()
                break
            
            except Exception as e:
                logger.error(f"âŒ Error in iteration {iteration}: {e}", exc_info=True)
                # ç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£
                current_hypothesis = None
                current_expression = None
                continue
        
        # å¾ªç¯ç»“æŸ
        if iteration >= max_iterations:
            logger.info("\n" + "=" * 80)
            logger.info(f"â±ï¸ Reached maximum iterations ({max_iterations})")
            logger.info("=" * 80)
        
        self.print_summary()
    
    def add_to_hopeful_alphas(self, expression: str, result: AlphaResult, analysis: Dict):
        """
        æ·»åŠ  alpha åˆ° hopeful_alphas.json
        
        Args:
            expression: Alpha è¡¨è¾¾å¼
            result: æ¨¡æ‹Ÿç»“æœ
            analysis: Evaluator çš„åˆ†æ
        """
        # åŠ è½½ç°æœ‰æ•°æ®
        hopeful_alphas = []
        if self.hopeful_alphas_file.exists():
            with open(self.hopeful_alphas_file, 'r', encoding='utf-8') as f:
                hopeful_alphas = json.load(f)
        
        # æ·»åŠ æ–°æ•°æ®
        hopeful_alpha = {
            'expression': expression,
            'result': {
                'sharpe': result.sharpe,
                'fitness': result.fitness,
                'turnover': result.turnover,
                'returns': result.returns,
                'alpha_id': result.alpha_id
            },
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        }
        
        hopeful_alphas.append(hopeful_alpha)
        
        # ä¿å­˜
        with open(self.hopeful_alphas_file, 'w', encoding='utf-8') as f:
            json.dump(hopeful_alphas, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… Added to hopeful_alphas.json (total: {len(hopeful_alphas)})")
    
    def save_hypothesis(self, hypothesis: Dict):
        """
        ä¿å­˜ hypothesis åˆ° hypothesis.json
        """
        # åŠ è½½ç°æœ‰ hypotheses
        if self.hypothesis_file.exists():
            with open(self.hypothesis_file, 'r', encoding='utf-8') as f:
                hypotheses = json.load(f)
        else:
            hypotheses = []
        
        # æ·»åŠ æ—¶é—´æˆ³
        hypothesis['timestamp'] = datetime.now().isoformat()
        
        # æ·»åŠ åˆ°åˆ—è¡¨
        hypotheses.append(hypothesis)
        self.all_hypotheses.append(hypothesis)
        
        # ä¿å­˜
        with open(self.hypothesis_file, 'w', encoding='utf-8') as f:
            json.dump(hypotheses, f, indent=2, ensure_ascii=False)
    
    def save_history(self):
        """
        å®æ—¶ä¿å­˜ history åˆ° history.json
        """
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, indent=2, ensure_ascii=False)
    
    def print_summary(self):
        """æ‰“å°æ€»ç»“"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š Summary")
        logger.info("=" * 80)
        logger.info(f"Total iterations: {len(self.history)}")
        logger.info(f"Unique expressions tried: {len(self.all_expressions)}")
        logger.info(f"Hypotheses generated: {len(self.all_hypotheses)}")
        
        # è¯»å– hopeful alphas
        if self.hopeful_alphas_file.exists():
            with open(self.hopeful_alphas_file, 'r', encoding='utf-8') as f:
                hopeful_alphas = json.load(f)
            logger.info(f"Hopeful alphas: {len(hopeful_alphas)}")
        else:
            logger.info(f"Hopeful alphas: 0")
        
        # ç»“æœæ–‡ä»¶
        logger.info("\nğŸ“ Results saved to:")
        logger.info(f"   - {self.history_file}")
        logger.info(f"   - {self.hypothesis_file}")
        logger.info(f"   - {self.hopeful_alphas_file}")
        
        # æ˜¾ç¤ºæœ€ä½³å°è¯•
        if self.history:
            # ä» history ä¸­æ‰¾æœ€é«˜ Sharpe
            valid_history = [h for h in self.history if h.get('result', {}).get('success', False)]
            if valid_history:
                best = max(valid_history, key=lambda x: abs(x['result']['sharpe']))
                logger.info(f"\nğŸ“ˆ Best Sharpe in this run:")
                logger.info(f"   Expression: {best['expression']}")
                logger.info(f"   Sharpe: {best['result']['sharpe']:.3f}")
                logger.info(f"   Decision: {best.get('decision', 'N/A')}")


def preload_model(model_name: str = "gemma3:1b"):
    """
    é¢„åŠ è½½ Ollama æ¨¡å‹
    é€šè¿‡è¿è¡Œæ¨¡å‹ç„¶åç«‹å³é€€å‡ºæ¥ç¡®ä¿æ¨¡å‹å·²åŠ è½½åˆ°å†…å­˜
    """
    import subprocess
    
    logger.info(f"ğŸ”„ Preloading model: {model_name}...")
    try:
        # ä½¿ç”¨ echo '/bye' | ollama run æ¥è‡ªåŠ¨å¯åŠ¨å¹¶é€€å‡º
        process = subprocess.Popen(
            ['ollama', 'run', model_name],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # å‘é€ /bye å‘½ä»¤å¹¶ç­‰å¾…é€€å‡º
        stdout, stderr = process.communicate(input='/bye\n', timeout=30)
        
        if process.returncode == 0 or 'bye' in stdout.lower():
            logger.info(f"âœ… Model {model_name} loaded and ready")
        else:
            logger.warning(f"âš ï¸ Model preload completed with return code {process.returncode}")
    
    except subprocess.TimeoutExpired:
        process.kill()
        logger.warning(f"âš ï¸ Model preload timed out, but continuing...")
    except FileNotFoundError:
        logger.warning(f"âš ï¸ 'ollama' command not found. Model will be loaded on first use.")
    except Exception as e:
        logger.warning(f"âš ï¸ Could not preload model: {e}. Model will be loaded on first use.")


def main():
    """ä¸»å…¥å£"""
    try:
        # åŠ è½½é…ç½®ä»¥è·å–æ¨¡å‹åç§°
        config = ConfigLoader.all()
        model_name = config.get('ollama_model', 'gemma3:1b')
        
        # é¢„åŠ è½½æ¨¡å‹
        preload_model(model_name)
        
        # åˆå§‹åŒ–å¹¶è¿è¡Œ miner
        miner = AlphaMiner()
        miner.run(max_iterations=100)
    
    except Exception as e:
        logger.error(f"Fatal error: {e}", exc_info=True)
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

