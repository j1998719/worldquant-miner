"""
Alpha Miner - ä¸»å¾ªç¯
åè°ƒæ‰€æœ‰ Agents å®ç°è¿­ä»£ä¼˜åŒ–
"""
import logging
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

from core.wq_api import WorldQuantAPI, SimulationSettings, AlphaResult
from core.data_loader import DataLoader
from agents.alpha_designer_agent import AlphaDesignerAgent
from agents.metrics_analyzer import MetricsAnalyzer
from agents.expression_analyzer import ExpressionAnalyzer
from agents.suggestion_generator import SuggestionGenerator
from utils.config_loader import ConfigLoader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  # ä½¿ç”¨ INFO çº§åˆ«ï¼ˆå¦‚éœ€è°ƒè¯•å¯æ”¹ä¸º DEBUGï¼‰
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('alpha_miner.log')
    ]
)
logger = logging.getLogger(__name__)


class AlphaMiner:
    """
    Alpha Miner ä¸»ç±»
    å®ç°è¿­ä»£ä¼˜åŒ–å¾ªç¯ï¼šç”Ÿæˆå‡è®¾ -> è®¾è®¡è¡¨è¾¾å¼ -> æ¨¡æ‹Ÿ -> è¯„ä¼° -> ä¼˜åŒ–/é‡æ–°ç”Ÿæˆ
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ– Alpha Miner
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œå¦‚æœä¸º None åˆ™ä» config.yaml åŠ è½½
        """
        if config is None:
            config = ConfigLoader.all()
        
        self.config = config
        
        # åˆå§‹åŒ– WQ API
        self.wq_api = WorldQuantAPI(
            username=config['worldquant_account'],
            password=config['worldquant_password']
        )
        
        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self.data_loader = DataLoader(
            enabled_datasets=config.get('enabled_field_datasets', []),
            enabled_operators=config.get('enabled_operators', [])
        )
        
        # åŠ è½½ operators å’Œ fieldsï¼ˆå®Œæ•´æ•°æ®ï¼‰
        logger.info("Loading operators and fields...")
        self.operators_data = self.data_loader.load_operators()  # å®Œæ•´çš„ operators.json æ•°æ®
        self.fields_data = self.data_loader.load_fields()  # æ ¹æ® enabled_field_datasets åŠ è½½çš„å®Œæ•´ fields æ•°æ®
        self.enabled_datasets = config.get('enabled_field_datasets', [])
        
        logger.info(f"ğŸ“š Loaded {len(self.operators_data)} operators")
        logger.info(f"ğŸ“š Loaded {len(self.fields_data)} fields from datasets: {', '.join(self.enabled_datasets)}")
        
        # åˆå§‹åŒ– Agents
        ollama_config = {
            'ollama_url': config.get('ollama_url', 'http://localhost:11434'),
            'ollama_model': config.get('ollama_model', 'gemma3:1b'),
            'temperature': 0.5  # æé«˜åˆ›é€ åŠ›ï¼Œé¿å…é‡å¤
        }
        
        # Agent ç³»ç»Ÿï¼ˆç®€åŒ–ä¸º 4 ä¸ªä¸“æ³¨çš„ agentsï¼‰
        self.designer_agent = AlphaDesignerAgent(**ollama_config)  # ä» hopeful_alphas é€‰æ‹©è¡¨è¾¾å¼
        self.metrics_analyzer = MetricsAnalyzer(**ollama_config)    # åˆ†ææ€§èƒ½æŒ‡æ ‡
        self.expression_analyzer = ExpressionAnalyzer(**ollama_config)  # åˆ†æè¡¨è¾¾å¼ç»“æ„
        self.suggestion_generator = SuggestionGenerator(**ollama_config)  # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        
        # ç»“æœç›®å½•
        self.results_dir = Path("results")
        self.results_dir.mkdir(exist_ok=True)
        
        # æ–‡ä»¶è·¯å¾„ï¼ˆéƒ½åœ¨ results/ ä¸‹ï¼‰
        self.history_file = self.results_dir / "history.json"
        self.hopeful_alphas_file = self.results_dir / "hopeful_alphas.json"
        
        # æ¨¡æ‹Ÿè®¾ç½®
        self.sim_settings = SimulationSettings(
            region=config.get('worldquant_region', 'USA'),
            universe=config.get('worldquant_universe', 'TOP3000'),
            delay=1,
            neutralization="SUBINDUSTRY",
            truncation=0.08
        )
        
        # æˆåŠŸæ ‡å‡†ï¼ˆWorldQuant Brain's criteria - for reference onlyï¼‰
        self.success_criteria = {
            'min_sharpe': config.get('min_sharpe', 1.25),
            'min_fitness': config.get('min_fitness', 1.0),
            'max_turnover': config.get('max_turnover', 0.7),
            'min_turnover': config.get('min_turnover', 0.1),
            'min_returns': config.get('min_returns', 0.1)
        }
        
        # å†å²è®°å½•
        self.history = []
        self.all_expressions = []  # æ‰€æœ‰å°è¯•è¿‡çš„ expressionï¼ˆé˜²é‡å¤ï¼‰
        
        # åŠ è½½å·²æœ‰çš„å†å²è®°å½•ï¼ˆé˜²é‡å¤ï¼‰
        self._load_existing_history()
    
    def _validate_recommendations(self, data: Dict, data_type: str = "hypothesis") -> Dict[str, Any]:
        """
        Rule-based éªŒè¯ recommended_fields å’Œ recommended_operators
        
        Args:
            data: hypothesis æˆ– analysis å­—å…¸
            data_type: "hypothesis" æˆ– "analysis"
        
        Returns:
            {
                'valid': bool,
                'reason': str (if invalid),
                'invalid_fields': List[str],
                'invalid_operators': List[str]
            }
        """
        # ä»å®Œæ•´æ•°æ®ä¸­æå– field IDs å’Œ operator names
        available_fields = set(f.get('id', f.get('name', '')) for f in self.fields_data)
        available_operators = set(op.get('name', '') for op in self.operators_data)
        
        recommended_fields = data.get('recommended_fields', [])
        recommended_operators = data.get('recommended_operators', [])
        
        # æ£€æŸ¥ fields
        invalid_fields = [f for f in recommended_fields if f not in available_fields]
        
        # æ£€æŸ¥ operators
        invalid_operators = [op for op in recommended_operators if op not in available_operators]
        
        if invalid_fields or invalid_operators:
            reason = []
            if invalid_fields:
                reason.append(f"{len(invalid_fields)}/{len(recommended_fields)} fields not found")
            if invalid_operators:
                reason.append(f"{len(invalid_operators)}/{len(recommended_operators)} operators not found")
            
            return {
                'valid': False,
                'reason': ', '.join(reason),
                'invalid_fields': invalid_fields,
                'invalid_operators': invalid_operators
            }
        
        return {'valid': True}
    
    def _check_success_criteria(self, result: AlphaResult) -> bool:
        """
        æ£€æŸ¥ alpha æ˜¯å¦æ»¡è¶³æ‰€æœ‰æˆåŠŸæ ‡å‡†
        
        Args:
            result: AlphaResult object
        
        Returns:
            bool: True if meets all criteria, False otherwise
        """
        meets_sharpe = result.sharpe >= self.success_criteria['min_sharpe']
        meets_fitness = result.fitness >= self.success_criteria['min_fitness']
        meets_turnover_min = result.turnover >= self.success_criteria['min_turnover']
        meets_turnover_max = result.turnover <= self.success_criteria['max_turnover']
        meets_returns = result.returns >= self.success_criteria['min_returns']
        
        return all([meets_sharpe, meets_fitness, meets_turnover_min, meets_turnover_max, meets_returns])
    
    def _load_existing_history(self):
        """
        ä» history.json å’Œ hypothesis.json åŠ è½½å·²æœ‰æ•°æ®ï¼ˆé˜²é‡å¤ï¼‰
        """
        # åŠ è½½ history.json
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    existing_history = json.load(f)
                
                # åŠ è½½åˆ° self.historyï¼ˆç”¨äºç»§ç»­ iteration è®¡æ•°ï¼‰
                self.history = existing_history
                
                # æå–æ‰€æœ‰å·²å°è¯•è¿‡çš„ expressions
                for record in existing_history:
                    expr = record.get('expression')
                    if expr and expr not in self.all_expressions:
                        self.all_expressions.append(expr)
                
                logger.info(f"ğŸ“‹ Loaded {len(existing_history)} history records, {len(self.all_expressions)} unique expressions")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load history.json: {e}")
    
    def run(self, max_iterations: int = None):
        """
        è¿è¡Œä¸»å¾ªç¯ï¼šä¸æ–­ç”Ÿæˆå’Œæµ‹è¯• alphasï¼Œç›´åˆ°æ‰¾åˆ°æ»¡è¶³æ‰€æœ‰ criteria çš„ alpha
        
        Rule-based ç­–ç•¥ï¼š
        - Sharpe > 1.0 â†’ åŠ å…¥ hopeful_alphas.jsonï¼Œæ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‰€æœ‰ criteria
        - Sharpe < -1.0 â†’ åè½¬ååŠ å…¥ hopeful_alphas.jsonï¼Œæ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‰€æœ‰ criteria
        - abs(Sharpe) < 1.0 â†’ æ”¾å¼ƒï¼Œé€‰æ‹©æ–°è¡¨è¾¾å¼
        
        Args:
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆNone = æ— é™å¾ªç¯ç›´åˆ°æˆåŠŸï¼‰
        """
        logger.info("=" * 80)
        logger.info("ğŸš€ Alpha Miner Started (Rule-based Strategy)")
        logger.info("=" * 80)
        logger.info("ğŸ“‹ Decision Rules:")
        logger.info("   âœ… Sharpe > 1.0  â†’ Add to hopeful_alphas.json")
        logger.info("   ğŸ”„ Sharpe < -1.0 â†’ Reverse & add to hopeful_alphas.json")
        logger.info("   âŒ |Sharpe| < 1.0 â†’ Abandon, select new expression")
        logger.info("")
        logger.info(f"ğŸ¯ WorldQuant Success Criteria (MUST meet ALL to stop):")
        logger.info(f"   Sharpe >= {self.success_criteria['min_sharpe']}")
        logger.info(f"   Fitness >= {self.success_criteria['min_fitness']}")
        logger.info(f"   {self.success_criteria['min_turnover']} <= Turnover <= {self.success_criteria['max_turnover']}")
        logger.info(f"   Returns >= {self.success_criteria['min_returns']}")
        if max_iterations:
            logger.info(f"\nâ±ï¸  Max iterations: {max_iterations}")
        else:
            logger.info(f"\nâ™¾ï¸  Unlimited iterations (will run until success)")
        logger.info("=" * 80)
        
        # ä»ç°æœ‰ history ç»§ç»­ï¼ˆå¦‚æœæœ‰ï¼‰
        iteration = len(self.history)
        current_expression = None
        
        while True:  # æ— é™å¾ªç¯ï¼Œç›´åˆ°æ‰¾åˆ°æˆåŠŸçš„ alpha æˆ–è¾¾åˆ° max_iterations
            iteration += 1
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            if max_iterations and iteration > max_iterations:
                logger.info("\n" + "=" * 80)
                logger.info(f"â±ï¸ Reached maximum iterations ({max_iterations})")
                logger.info("=" * 80)
                break
            
            logger.info(f"\n{'=' * 80}")
            if max_iterations:
                logger.info(f"ğŸ“ Iteration {iteration}/{max_iterations}")
            else:
                logger.info(f"ğŸ“ Iteration {iteration}")
            logger.info(f"{'=' * 80}")
            
            try:
                # æ”¶é›†ä¹‹å‰å°è¯•è¿‡çš„ expressionsï¼ˆç”¨äºé¿å…é‡å¤ï¼‰
                previous_expressions = [h['expression'] for h in self.history if 'expression' in h]
                
                # Step 1: ä» hopeful_alphas.json ä¸­é€‰æ‹©è¡¨è¾¾å¼
                logger.info("\nğŸ¨ Step 1: Selecting Expression from Hopeful Alphas...")
                
                design_result = self.designer_agent.execute({
                    'previous_attempts': self.all_expressions
                })
                
                if not design_result['success']:
                    logger.error(f"Expression selection failed: {design_result['error']}")
                    continue
                
                alpha_design = design_result['alpha_design']
                current_expression = alpha_design['expression']
                
                # æ£€æŸ¥é‡å¤
                if current_expression in self.all_expressions:
                    logger.warning(f"âš ï¸ Expression already tried: {current_expression}")
                    logger.warning("   This should not happen, but continuing...")
                    continue
                
                self.all_expressions.append(current_expression)
                logger.info(f"âœ… Expression selected: {current_expression}")
                logger.info(f"   Source: {alpha_design.get('source', 'unknown')}")
                
                # éªŒè¯è¡¨è¾¾å¼
                validation = self.data_loader.validate_expression(current_expression)
                if not validation['valid']:
                    logger.warning(f"âš ï¸ Invalid expression:")
                    logger.warning(f"  Unknown operators: {validation['unknown_operators']}")
                    logger.warning(f"  Unknown fields: {validation['unknown_fields']}")
                    # ç»§ç»­æ‰§è¡Œï¼Œè®© WQ API è¿”å›å…·ä½“é”™è¯¯
                
                # Step 2: æäº¤æ¨¡æ‹Ÿ
                logger.info("\nâš™ï¸ Step 2: Submitting Simulation...")
                result = self.wq_api.simulate_alpha(current_expression, self.sim_settings)
                
                if result is None:
                    logger.error("âŒ Simulation failed to submit")
                    current_expression = None
                    continue
                
                # æ˜¾ç¤ºç»“æœ
                logger.info(f"\nğŸ“Š Results:")
                logger.info(f"  Sharpe:   {result.sharpe:.3f}")
                logger.info(f"  Fitness:  {result.fitness:.3f}")
                logger.info(f"  Turnover: {result.turnover:.3f}")
                logger.info(f"  Returns:  {result.returns:.3f}")
                
                # é¢„åˆ¤å†³ç­–
                if result.sharpe > 1.0:
                    logger.info(f"  âœ… Sharpe > 1.0 â†’ Will add to hopeful!")
                elif result.sharpe < -1.0:
                    logger.info(f"  ğŸ”„ Sharpe < -1.0 â†’ Will reverse & add to hopeful!")
                else:
                    logger.info(f"  âŒ |Sharpe| < 1.0 â†’ Will abandon")
                
                # Step 4: Rule-based å†³ç­–
                logger.info("\nğŸ“ˆ Step 4: Rule-based Decision...")
                
                sharpe = result.sharpe
                
                # ä¿å­˜å½“å‰çš„ expressionï¼ˆç”¨äºè®°å½• historyï¼‰
                record_expression = current_expression
                
                # Rule 1: Sharpe > 1.0 â†’ Hopeful alpha!
                if sharpe > 1.0:
                    logger.info("âœ… HOPEFUL! Sharpe > 1.0")
                    logger.info("   Analyzing alpha with 3-stage pipeline...")
                    
                    # Stage 1: åˆ†ææ€§èƒ½æŒ‡æ ‡
                    logger.info("   ğŸ“Š Stage 1: Metrics Analysis...")
                    metrics_result = self.metrics_analyzer.execute({
                        'result': result,
                        'criteria': self.success_criteria
                    })
                    
                    # Stage 2: åˆ†æè¡¨è¾¾å¼ç»“æ„
                    logger.info("   ğŸ” Stage 2: Expression Analysis...")
                    expression_result = self.expression_analyzer.execute({
                        'expression': current_expression,
                        'operators_data': self.operators_data,
                        'fields_data': self.fields_data,
                        'enabled_datasets': self.enabled_datasets
                    })
                    
                    # Stage 3: ç”Ÿæˆä¼˜åŒ–å»ºè®®
                    if metrics_result['success'] and expression_result['success']:
                        logger.info("   ğŸ’¡ Stage 3: Generating Suggestions...")
                        suggestion_result = self.suggestion_generator.execute({
                            'expression': current_expression,
                            'metrics_analysis': metrics_result['analysis'],
                            'expression_analysis': expression_result['analysis'],
                            'operators_data': self.operators_data,
                            'fields_data': self.fields_data,
                            'enabled_datasets': self.enabled_datasets
                        })
                        
                        if suggestion_result['success']:
                            # ç»„åˆåˆ†æç»“æœ
                            analysis = {
                                'metrics': metrics_result['analysis'],
                                'expression': expression_result['analysis'],
                                'suggested_expressions': suggestion_result['suggestions']
                            }
                            
                            self.add_to_hopeful_alphas(current_expression, result, analysis)
                            logger.info(f"   âœ… Added with {len(suggestion_result['suggestions'])} suggestions")
                            
                            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‰€æœ‰æˆåŠŸæ ‡å‡†
                            if self._check_success_criteria(result):
                                logger.info("\n" + "ğŸ‰" * 40)
                                logger.info("ğŸ‰ SUCCESS! Found alpha that meets ALL criteria!")
                                logger.info("ğŸ‰" * 40)
                                logger.info(f"\nâœ… Expression: {current_expression}")
                                logger.info(f"   Sharpe:   {result.sharpe:.3f} (>= {self.success_criteria['min_sharpe']}) âœ…")
                                logger.info(f"   Fitness:  {result.fitness:.3f} (>= {self.success_criteria['min_fitness']}) âœ…")
                                logger.info(f"   Turnover: {result.turnover:.3f} ({self.success_criteria['min_turnover']}-{self.success_criteria['max_turnover']}) âœ…")
                                logger.info(f"   Returns:  {result.returns:.3f} (>= {self.success_criteria['min_returns']}) âœ…")
                                logger.info(f"   Alpha ID: {result.alpha_id}")
                                logger.info("\n" + "ğŸ‰" * 40)
                                self.save_history()
                                self.print_summary()
                                return  # æˆåŠŸï¼åœæ­¢å¾ªç¯
                        else:
                            logger.warning(f"   âš ï¸ Suggestion generation failed: {suggestion_result['error']}")
                    else:
                        logger.warning("   âš ï¸ Analysis failed, skipping...")
                    
                    # ç»§ç»­æœç´¢æ›´å¥½çš„ alpha
                    current_expression = None
                
                # Rule 2: Sharpe < -1.0 â†’ Reverse and add to hopeful!
                elif sharpe < -1.0:
                    logger.info(f"ğŸ”„ REVERSE! Sharpe={sharpe:.3f} < -1.0")
                    logger.info(f"   Multiplying by -1 would give Sharpeâ‰ˆ{-sharpe:.3f}")
                    
                    reversed_expression = f"(-1 * ({current_expression}))"
                    logger.info(f"   Reversed: {reversed_expression}")
                    logger.info("   Analyzing reversed alpha with 3-stage pipeline...")
                    
                    # åˆ›å»ºåè½¬åçš„è™šæ‹Ÿ result
                    reversed_result_data = AlphaResult(
                        alpha_id=result.alpha_id,
                        expression=reversed_expression,
                        sharpe=-result.sharpe,
                        fitness=-result.fitness,
                        turnover=result.turnover,
                        returns=-result.returns,
                        drawdown=result.drawdown,
                        margin=result.margin,
                        longCount=result.shortCount,
                        shortCount=result.longCount,
                        success=True
                    )
                    
                    # Stage 1: åˆ†ææ€§èƒ½æŒ‡æ ‡
                    logger.info("   ğŸ“Š Stage 1: Metrics Analysis...")
                    metrics_result = self.metrics_analyzer.execute({
                        'result': reversed_result_data,
                        'criteria': self.success_criteria
                    })
                    
                    # Stage 2: åˆ†æè¡¨è¾¾å¼ç»“æ„
                    logger.info("   ğŸ” Stage 2: Expression Analysis...")
                    expression_result = self.expression_analyzer.execute({
                        'expression': reversed_expression,
                        'operators_data': self.operators_data,
                        'fields_data': self.fields_data,
                        'enabled_datasets': self.enabled_datasets
                    })
                    
                    # Stage 3: ç”Ÿæˆä¼˜åŒ–å»ºè®®
                    if metrics_result['success'] and expression_result['success']:
                        logger.info("   ğŸ’¡ Stage 3: Generating Suggestions...")
                        suggestion_result = self.suggestion_generator.execute({
                            'expression': reversed_expression,
                            'metrics_analysis': metrics_result['analysis'],
                            'expression_analysis': expression_result['analysis'],
                            'operators_data': self.operators_data,
                            'fields_data': self.fields_data,
                            'enabled_datasets': self.enabled_datasets
                        })
                        
                        if suggestion_result['success']:
                            # ç»„åˆåˆ†æç»“æœ
                            analysis = {
                                'metrics': metrics_result['analysis'],
                                'expression': expression_result['analysis'],
                                'suggested_expressions': suggestion_result['suggestions']
                            }
                            
                            self.add_to_hopeful_alphas(reversed_expression, reversed_result_data, analysis)
                            logger.info(f"   âœ… Added reversed alpha with {len(suggestion_result['suggestions'])} suggestions")
                            
                            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‰€æœ‰æˆåŠŸæ ‡å‡†
                            if self._check_success_criteria(reversed_result_data):
                                logger.info("\n" + "ğŸ‰" * 40)
                                logger.info("ğŸ‰ SUCCESS! Found alpha that meets ALL criteria!")
                                logger.info("ğŸ‰" * 40)
                                logger.info(f"\nâœ… Expression: {reversed_expression}")
                                logger.info(f"   Sharpe:   {reversed_result_data.sharpe:.3f} (>= {self.success_criteria['min_sharpe']}) âœ…")
                                logger.info(f"   Fitness:  {reversed_result_data.fitness:.3f} (>= {self.success_criteria['min_fitness']}) âœ…")
                                logger.info(f"   Turnover: {reversed_result_data.turnover:.3f} ({self.success_criteria['min_turnover']}-{self.success_criteria['max_turnover']}) âœ…")
                                logger.info(f"   Returns:  {reversed_result_data.returns:.3f} (>= {self.success_criteria['min_returns']}) âœ…")
                                logger.info(f"   Alpha ID: {reversed_result_data.alpha_id}")
                                logger.info("\n" + "ğŸ‰" * 40)
                                self.save_history()
                                self.print_summary()
                                return  # æˆåŠŸï¼åœæ­¢å¾ªç¯
                        else:
                            logger.warning(f"   âš ï¸ Suggestion generation failed: {suggestion_result['error']}")
                    else:
                        logger.warning("   âš ï¸ Analysis failed, skipping...")
                    
                    # ç»§ç»­æœç´¢
                    current_expression = None
                
                # Rule 3: abs(Sharpe) < 1.0 â†’ Abandon, try new expression
                else:
                    logger.info(f"âŒ ABANDON! abs(Sharpe)={abs(sharpe):.3f} < 1.0")
                    logger.info("   Selecting new expression...")
                    
                    # æ”¾å¼ƒï¼Œé€‰æ‹©æ–°è¡¨è¾¾å¼
                    current_expression = None
                
                # è®°å½•å†å²ï¼ˆè¯¦ç»†è®°å½•ï¼‰
                self.history.append({
                    'iteration': iteration,
                    'hypothesis': None,  # ä¸å†ä½¿ç”¨ hypothesis
                    'expression': record_expression,
                    'result': {
                        'sharpe': result.sharpe,
                        'fitness': result.fitness,
                        'turnover': result.turnover,
                        'returns': result.returns,
                        'alpha_id': result.alpha_id,
                        'success': result.success,
                        'error_message': result.error_message
                    },
                    'decision': 'HOPEFUL' if sharpe > 1.0 else ('REVERSE' if sharpe < -1.0 else 'ABANDON'),
                    'timestamp': datetime.now().isoformat()
                })
                
                # å®æ—¶ä¿å­˜ history
                self.save_history()
            
            except KeyboardInterrupt:
                logger.info("\nâš ï¸ Interrupted by user")
                self.save_history()
                break
            
            except Exception as e:
                logger.error(f"âŒ Error in iteration {iteration}: {e}", exc_info=True)
                # ç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£
                current_expression = None
                continue
        
        # å¾ªç¯ç»“æŸï¼ˆåªæœ‰åœ¨è¾¾åˆ° max_iterations æˆ–ç”¨æˆ·ä¸­æ–­æ—¶æ‰ä¼šåˆ°è¾¾è¿™é‡Œï¼‰
        self.print_summary()
    
    def add_to_hopeful_alphas(self, expression: str, result: AlphaResult, analysis: Dict):
        """
        æ·»åŠ  alpha åˆ° hopeful_alphas.json
        
        Args:
            expression: Alpha è¡¨è¾¾å¼
            result: æ¨¡æ‹Ÿç»“æœ
            analysis: Evaluator çš„åˆ†æ
        """
        # åŠ è½½ç°æœ‰æ•°æ®
        hopeful_alphas = []
        if self.hopeful_alphas_file.exists():
            with open(self.hopeful_alphas_file, 'r', encoding='utf-8') as f:
                hopeful_alphas = json.load(f)
        
        # æ·»åŠ æ–°æ•°æ®
        hopeful_alpha = {
            'expression': expression,
            'result': {
                'sharpe': result.sharpe,
                'fitness': result.fitness,
                'turnover': result.turnover,
                'returns': result.returns,
                'alpha_id': result.alpha_id
            },
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        }
        
        hopeful_alphas.append(hopeful_alpha)
        
        # ä¿å­˜
        with open(self.hopeful_alphas_file, 'w', encoding='utf-8') as f:
            json.dump(hopeful_alphas, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… Added to hopeful_alphas.json (total: {len(hopeful_alphas)})")
    
    def save_history(self):
        """
        å®æ—¶ä¿å­˜ history åˆ° history.json
        """
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, indent=2, ensure_ascii=False)
    
    def print_summary(self):
        """æ‰“å°æ€»ç»“"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š Summary")
        logger.info("=" * 80)
        logger.info(f"Total iterations: {len(self.history)}")
        logger.info(f"Unique expressions tried: {len(self.all_expressions)}")
        
        # è¯»å– hopeful alphas
        if self.hopeful_alphas_file.exists():
            with open(self.hopeful_alphas_file, 'r', encoding='utf-8') as f:
                hopeful_alphas = json.load(f)
            logger.info(f"Hopeful alphas: {len(hopeful_alphas)}")
        else:
            logger.info(f"Hopeful alphas: 0")
        
        # ç»“æœæ–‡ä»¶
        logger.info("\nğŸ“ Results saved to:")
        logger.info(f"   - {self.history_file}")
        logger.info(f"   - {self.hopeful_alphas_file}")
        
        # æ˜¾ç¤ºæœ€ä½³å°è¯•
        if self.history:
            # ä» history ä¸­æ‰¾æœ€é«˜ Sharpe
            valid_history = [h for h in self.history if h.get('result', {}).get('success', False)]
            if valid_history:
                best = max(valid_history, key=lambda x: abs(x['result']['sharpe']))
                logger.info(f"\nğŸ“ˆ Best Sharpe in this run:")
                logger.info(f"   Expression: {best['expression']}")
                logger.info(f"   Sharpe: {best['result']['sharpe']:.3f}")
                logger.info(f"   Decision: {best.get('decision', 'N/A')}")


def preload_model(model_name: str = "gemma3:1b"):
    """
    é¢„åŠ è½½ Ollama æ¨¡å‹
    é€šè¿‡è¿è¡Œæ¨¡å‹ç„¶åç«‹å³é€€å‡ºæ¥ç¡®ä¿æ¨¡å‹å·²åŠ è½½åˆ°å†…å­˜
    """
    import subprocess
    
    logger.info(f"ğŸ”„ Preloading model: {model_name}...")
    try:
        # ä½¿ç”¨ echo '/bye' | ollama run æ¥è‡ªåŠ¨å¯åŠ¨å¹¶é€€å‡º
        process = subprocess.Popen(
            ['ollama', 'run', model_name],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # å‘é€ /bye å‘½ä»¤å¹¶ç­‰å¾…é€€å‡º
        stdout, stderr = process.communicate(input='/bye\n', timeout=30)
        
        if process.returncode == 0 or 'bye' in stdout.lower():
            logger.info(f"âœ… Model {model_name} loaded and ready")
        else:
            logger.warning(f"âš ï¸ Model preload completed with return code {process.returncode}")
    
    except subprocess.TimeoutExpired:
        process.kill()
        logger.warning(f"âš ï¸ Model preload timed out, but continuing...")
    except FileNotFoundError:
        logger.warning(f"âš ï¸ 'ollama' command not found. Model will be loaded on first use.")
    except Exception as e:
        logger.warning(f"âš ï¸ Could not preload model: {e}. Model will be loaded on first use.")


def main():
    """ä¸»å…¥å£"""
    try:
        # åŠ è½½é…ç½®ä»¥è·å–æ¨¡å‹åç§°
        config = ConfigLoader.all()
        model_name = config.get('ollama_model', 'gemma3:1b')
        
        # é¢„åŠ è½½æ¨¡å‹
        preload_model(model_name)
        
        # åˆå§‹åŒ–å¹¶è¿è¡Œ minerï¼ˆæ— é™å¾ªç¯ç›´åˆ°æˆåŠŸï¼‰
        miner = AlphaMiner()
        miner.run()  # æ— é™å¾ªç¯ï¼Œç›´åˆ°æ‰¾åˆ°æ»¡è¶³æ‰€æœ‰ criteria çš„ alpha
    
    except Exception as e:
        logger.error(f"Fatal error: {e}", exc_info=True)
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

