"""
LangGraph State Definitions for WorldQuant Alpha Consultant
Defines TypedDict structures for managing state across the workflow
"""

from typing import TypedDict, List, Dict, Optional, Literal
from dataclasses import dataclass


# ============================================================================
# Data Classes for Structured Data
# ============================================================================

@dataclass
class Paper:
    """Academic paper metadata"""
    title: str
    authors: List[str]
    abstract: str
    url: str
    source: str  # 'arxiv', 'ssrn', 'google_scholar'
    published_date: str


@dataclass
class AlphaIdea:
    """Alpha trading hypothesis"""
    idea_id: str
    hypothesis: str
    rationale: str
    datasets: List[str]
    source: str  # paper title or 'refinement'
    source_url: Optional[str]
    timestamp: str
    parent_idea_id: Optional[str] = None  # For refinement tracking


@dataclass
class AlphaExpression:
    """WorldQuant Brain alpha expression"""
    expression_id: str
    expression: str  # The actual alpha formula
    parent_idea_id: str
    variant_type: str  # 'base', 'ranked', 'neutralized', etc.
    parameters: Dict  # Lookback windows, delays, etc.
    fingerprint: str  # For deduplication
    timestamp: str


@dataclass
class SimulationResult:
    """Result from WorldQuant Brain API simulation"""
    expression_id: str
    expression: str
    status: Literal['success', 'error']

    # Performance metrics (None if error)
    sharpe: Optional[float]
    fitness: Optional[float]
    returns: Optional[float]
    turnover: Optional[float]
    drawdown: Optional[float]
    margin: Optional[float]
    long_count: Optional[int]
    short_count: Optional[int]

    # Error information
    error: Optional[str]

    # Metadata
    alpha_id: Optional[str]  # WorldQuant Brain alpha ID
    timestamp: str


@dataclass
class EvaluationDecision:
    """Decision from evaluation agent"""
    expression_id: str
    decision: Literal['hopeful', 'reject', 'refine_negate', 'refine_adjust']
    reason: str
    sharpe: float
    fitness: float
    suggested_modifications: Optional[List[str]]  # For refinement
    timestamp: str


# ============================================================================
# LangGraph State TypedDict
# ============================================================================

class AlphaWorkflowState(TypedDict, total=False):
    """
    Complete state for the LangGraph alpha discovery workflow

    Note: total=False allows optional keys
    """

    # ===== Input Configuration =====
    research_topic: str  # e.g., "momentum", "value", "volatility"
    search_keywords: List[str]  # Additional keywords for paper search
    max_iterations: int  # Maximum refinement cycles
    ideas_per_cycle: int  # How many ideas to generate per cycle

    # ===== Research Phase =====
    papers_found: List[Dict]  # Raw paper dicts from search APIs
    papers_analyzed: List[Paper]  # Structured paper objects

    # ===== Idea Generation Phase =====
    ideas_extracted: List[Dict]  # Ideas extracted from papers
    ideas_generated: List[Dict]  # Ideas generated by LLM
    ideas_expanded: List[Dict]  # Variant ideas
    all_ideas: List[AlphaIdea]  # Combined structured ideas

    # ===== Formula Generation Phase =====
    expressions_generated: List[Dict]  # Raw expression dicts
    expressions_deduplicated: List[AlphaExpression]  # After dedup

    # ===== Simulation Phase =====
    simulation_queue: List[str]  # Expression IDs to simulate
    simulation_results: List[SimulationResult]  # Results from WorldQuant API

    # ===== Evaluation Phase =====
    evaluation_decisions: List[EvaluationDecision]  # Decisions for each result
    hopeful_alphas: List[Dict]  # Production-ready alphas
    rejected_alphas: List[Dict]  # Failed alphas
    refinement_candidates: List[Dict]  # Alphas to refine

    # ===== Refinement Phase =====
    refined_expressions: List[AlphaExpression]  # After refinement
    refinement_iteration: int  # Current refinement iteration

    # ===== Control Flow =====
    current_phase: str  # 'research', 'generate', 'simulate', 'evaluate', 'refine'
    iteration_count: int  # Overall workflow iteration
    should_continue: bool  # Whether to continue or end
    next_action: Literal['research', 'refine', 'end']  # Routing decision

    # ===== Statistics and Logging =====
    total_papers_searched: int
    total_ideas_generated: int
    total_expressions_tested: int
    total_duplicates_filtered: int
    total_hopeful_found: int

    # ===== Error Tracking =====
    errors: List[Dict]  # List of error dicts with context

    # ===== Cycle Metadata =====
    cycle_id: str  # Unique cycle identifier
    start_time: str  # ISO timestamp
    end_time: Optional[str]  # ISO timestamp when complete


# ============================================================================
# Helper Functions for State Management
# ============================================================================

def create_initial_state(
    research_topic: str,
    search_keywords: Optional[List[str]] = None,
    ideas_per_cycle: int = 5,
    max_iterations: int = 3
) -> AlphaWorkflowState:
    """
    Create initial workflow state

    Args:
        research_topic: Main research topic
        search_keywords: Additional search keywords
        ideas_per_cycle: Number of ideas per cycle
        max_iterations: Maximum refinement iterations

    Returns:
        Initialized AlphaWorkflowState
    """
    from datetime import datetime

    return AlphaWorkflowState(
        # Input
        research_topic=research_topic,
        search_keywords=search_keywords or [],
        max_iterations=max_iterations,
        ideas_per_cycle=ideas_per_cycle,

        # Empty collections
        papers_found=[],
        papers_analyzed=[],
        ideas_extracted=[],
        ideas_generated=[],
        ideas_expanded=[],
        all_ideas=[],
        expressions_generated=[],
        expressions_deduplicated=[],
        simulation_queue=[],
        simulation_results=[],
        evaluation_decisions=[],
        hopeful_alphas=[],
        rejected_alphas=[],
        refinement_candidates=[],
        refined_expressions=[],

        # Control
        current_phase='research',
        iteration_count=0,
        refinement_iteration=0,
        should_continue=True,
        next_action='research',

        # Statistics
        total_papers_searched=0,
        total_ideas_generated=0,
        total_expressions_tested=0,
        total_duplicates_filtered=0,
        total_hopeful_found=0,

        # Metadata
        errors=[],
        cycle_id=f"cycle_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        start_time=datetime.now().isoformat(),
        end_time=None
    )


def update_statistics(state: AlphaWorkflowState) -> AlphaWorkflowState:
    """
    Update statistics in the state based on current data

    Args:
        state: Current workflow state

    Returns:
        Updated state with recalculated statistics
    """
    state['total_papers_searched'] = len(state.get('papers_found', []))
    state['total_ideas_generated'] = len(state.get('all_ideas', []))
    state['total_expressions_tested'] = len(state.get('simulation_results', []))
    state['total_hopeful_found'] = len(state.get('hopeful_alphas', []))

    return state


def get_state_summary(state: AlphaWorkflowState) -> Dict:
    """
    Get a summary of the current state for logging

    Args:
        state: Current workflow state

    Returns:
        Dict with key statistics
    """
    return {
        'cycle_id': state.get('cycle_id', 'unknown'),
        'current_phase': state.get('current_phase', 'unknown'),
        'iteration': state.get('iteration_count', 0),
        'refinement_iteration': state.get('refinement_iteration', 0),
        'papers_found': len(state.get('papers_found', [])),
        'ideas_generated': len(state.get('all_ideas', [])),
        'expressions_tested': len(state.get('simulation_results', [])),
        'hopeful_alphas': len(state.get('hopeful_alphas', [])),
        'rejected_alphas': len(state.get('rejected_alphas', [])),
        'refinement_candidates': len(state.get('refinement_candidates', [])),
        'duplicates_filtered': state.get('total_duplicates_filtered', 0)
    }
