# WorldQuant Alpha Brain Consultant

**LangGraph + Ollama Cloud Edition**

Automated alpha discovery pipeline that researches academic papers, generates alpha hypotheses, converts them to WorldQuant Brain expressions, and tests them using the real WorldQuant Brain API with iterative refinement.

---

## ðŸŽ¯ Features

- **ðŸ“š Parallel Paper Research** - Searches arXiv, SSRN, Google Scholar simultaneously
- **ðŸ’¡ LLM-Powered Idea Generation** - Uses Ollama Cloud (gpt-oss:120b) to generate and expand alpha ideas
- **âš¡ Formula Generation** - Converts ideas to WorldQuant Brain FASTEXPR formulas
- **ðŸ§ª Real Backtesting** - Simulates alphas on WorldQuant Brain API
- **ðŸ”„ Iterative Refinement** - Automatically improves underperforming alphas (negation, parameter tuning)
- **ðŸ” Deduplication** - SHA256 fingerprints prevent testing duplicate alphas
- **ðŸ“Š Structured Logging** - Per-cycle and per-agent logs for complete audit trail

---

## ðŸ“‹ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LangGraph StateGraph Workflow                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. Research Papers (Parallel)                       â”‚
    â”‚     - arXiv search                                   â”‚
    â”‚     - SSRN search (if configured)                    â”‚
    â”‚     - Google Scholar (if configured)                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. Extract & Generate Ideas                         â”‚
    â”‚     - Extract ideas from papers (Ollama)             â”‚
    â”‚     - Generate new ideas (Ollama)                    â”‚
    â”‚     - Expand ideas into variants                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. Generate Formulas                                â”‚
    â”‚     - Convert ideas to FASTEXPR (Ollama)             â”‚
    â”‚     - Generate multiple variants per idea            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  4. Deduplicate                                      â”‚
    â”‚     - Check expression fingerprints                  â”‚
    â”‚     - Filter out duplicates                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  5. Simulate (WorldQuant Brain API)                  â”‚
    â”‚     - Real backtesting                               â”‚
    â”‚     - Get Sharpe, Fitness, Turnover                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  6. Evaluate Results                                 â”‚
    â”‚     - Hopeful: Sharpe > 1.5  â†’  Save                 â”‚
    â”‚     - Refineable: 0.5 < Sharpe < 1.5  â†’  Refine      â”‚
    â”‚     - Poor: Sharpe < 0.5  â†’  Reject                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  7. Decide Next Action                               â”‚
    â”‚     - Found â‰¥10 hopeful â†’ END                        â”‚
    â”‚     - Has refinement candidates â†’ REFINE             â”‚
    â”‚     - Iteration < max â†’ CONTINUE (new research)      â”‚
    â”‚     - Otherwise â†’ END                                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  8. Refinement (if needed)                           â”‚
    â”‚     - Negate signals (if Sharpe < 0)                 â”‚
    â”‚     - Adjust parameters (Ollama)                     â”‚
    â”‚     - Re-simulate refined alphas                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ Quick Start

### 1. Prerequisites

- Python 3.9+
- WorldQuant Brain account ([sign up here](https://platform.worldquantbrain.com))
- Ollama Cloud API key ([get one here](https://ollama.com))

### 2. Installation

```bash
cd consultant-langgraph/

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

Edit `config.yaml` to add your Ollama API key:

```yaml
ollama_api_key: your_api_key_here
```

WorldQuant credentials are already configured in `config/credentials.json`.

### 4. Run Your First Alpha Discovery

```bash
# Discover momentum alphas
python main.py momentum

# Value investing alphas
python main.py value --keywords "fundamental,earnings"

# Mean reversion with custom settings
python main.py "mean reversion" --ideas 10 --iterations 5

# Volatility strategies
python main.py volatility --keywords "variance,garch"
```

---

## ðŸ“– Usage

### Command Line Interface

```bash
python main.py <topic> [OPTIONS]
```

**Arguments:**
- `topic` - Research topic (e.g., "momentum", "value", "quality", "volatility")

**Options:**
- `--keywords` - Additional search keywords (comma-separated)
- `--ideas` - Number of ideas per cycle (default: 5)
- `--iterations` - Maximum iterations (default: 3)
- `--config` - Path to config file (default: config/langgraph_config.json)
- `--log-level` - Logging level: DEBUG, INFO, WARNING, ERROR (default: INFO)
- `--no-console` - Disable console output, only log to files

### Examples

```bash
# Basic momentum research
python main.py momentum

# Deep dive into value with many ideas
python main.py value --ideas 20 --iterations 5

# Quality investing with specific factors
python main.py quality --keywords "profitability,stability,growth"

# High-frequency mean reversion
python main.py "mean reversion" --keywords "microstructure,volatility"

# Debug mode with verbose logging
python main.py momentum --log-level DEBUG
```

---

## ðŸ“ Project Structure

```
consultant-langgraph/
â”œâ”€â”€ main.py                      # CLI entry point
â”œâ”€â”€ alpha_workflow.py            # LangGraph StateGraph workflow
â”œâ”€â”€ graph_state.py               # State definitions
â”‚
â”œâ”€â”€ Agents/
â”‚   â”œâ”€â”€ base_agent.py            # Base class for all agents
â”‚   â”œâ”€â”€ paper_research_agent.py  # Paper search & analysis
â”‚   â”œâ”€â”€ idea_agent.py            # Idea generation & expansion
â”‚   â”œâ”€â”€ factor_agent.py          # Formula generation
â”‚   â”œâ”€â”€ simulation_agent.py      # WorldQuant Brain API client
â”‚   â”œâ”€â”€ eval_agent.py            # Result evaluation
â”‚   â””â”€â”€ refinement_agent.py      # Alpha improvement
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logging_config.py        # Structured logging
â”‚   â””â”€â”€ deduplication.py         # Expression history tracking
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ langgraph_config.json    # Main configuration
â”‚   â””â”€â”€ credentials.json         # WorldQuant credentials
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ idea_generation.txt      # Idea generation prompt
â”‚   â”œâ”€â”€ formula_generation.txt   # Formula conversion prompt
â”‚   â”œâ”€â”€ paper_analysis.txt       # Paper extraction prompt
â”‚   â””â”€â”€ refinement.txt           # Refinement prompt
â”‚
â”œâ”€â”€ data/                        # Generated data (auto-created)
â”‚   â”œâ”€â”€ hopeful_alphas.json
â”‚   â”œâ”€â”€ rejected_alphas.json
â”‚   â”œâ”€â”€ alpha_ideas.json
â”‚   â”œâ”€â”€ simulation_results.json
â”‚   â””â”€â”€ expression_history.json
â”‚
â””â”€â”€ logs/                        # Logs (auto-created)
    â”œâ”€â”€ main.log
    â”œâ”€â”€ cycles/
    â”‚   â””â”€â”€ cycle_YYYYMMDD_HHMMSS.log
    â””â”€â”€ agents/
        â”œâ”€â”€ paper_research.log
        â”œâ”€â”€ idea_agent.log
        â”œâ”€â”€ factor_agent.log
        â”œâ”€â”€ simulation_agent.log
        â”œâ”€â”€ eval_agent.log
        â””â”€â”€ refinement_agent.log
```

---

## âš™ï¸ Configuration

### Main Config: `config/langgraph_config.json`

```json
{
  "ollama_url": "https://ollama.com",
  "cloud_model": "gpt-oss:120b",

  "workflow": {
    "ideas_per_cycle": 5,
    "max_iterations": 3,
    "enable_deduplication": true,
    "enable_refinement": true,
    "max_refinement_iterations": 2
  },

  "idea_agent": {
    "temperature": 0.8,
    "max_retries": 3
  },

  "factor_agent": {
    "temperature": 0.7,
    "expressions_per_idea": 2
  },

  "eval_agent": {
    "sharpe_threshold_hopeful": 1.5,
    "fitness_threshold_hopeful": 0.6,
    "sharpe_threshold_refine": 0.5
  }
}
```

### WorldQuant Credentials: `config/credentials.json`

```json
[
  "your_email@example.com",
  "your_password"
]
```

---

## ðŸ“Š Output

### Data Files

After running, check these files:

- **`data/hopeful_alphas.json`** - Production-ready alphas (Sharpe > 1.5)
- **`data/rejected_alphas.json`** - Failed alphas for learning
- **`data/alpha_ideas.json`** - All generated ideas
- **`data/simulation_results.json`** - Complete backtest results
- **`data/expression_history.json`** - Deduplication database

### Log Files

- **`logs/main.log`** - Main application log
- **`logs/cycles/cycle_*.log`** - Per-cycle execution log
- **`logs/agents/*.log`** - Per-agent activity logs

### Example Hopeful Alpha

```json
{
  "expression_id": "idea_003_expr2",
  "expression": "rank(ts_sum(close/delay(close,1)-1,60)/ts_std(returns,60))",
  "alpha_id": "WQ_ABC123",
  "sharpe": 1.82,
  "fitness": 0.73,
  "returns": 0.18,
  "turnover": 85.3,
  "drawdown": 0.12,
  "reason": "Excellent performance: Sharpe=1.82, Fitness=0.73",
  "timestamp": "2025-01-12T10:23:45"
}
```

---

## ðŸ”§ Troubleshooting

### Common Issues

**1. Ollama API Key Error**
```
Error: Ollama API error 401: Unauthorized
```
**Solution:** Check `config.yaml` has correct `ollama_api_key`

**2. WorldQuant Authentication Failed**
```
Error: Authentication failed: 401
```
**Solution:** Verify credentials in `config/credentials.json`

**3. No Papers Found**
```
Warning: arXiv search returned 0 papers
```
**Solution:** Try different keywords or topics, check internet connection

**4. All Expressions Duplicates**
```
Info: Filtered 25 duplicates, 0 novel expressions remain
```
**Solution:** Delete `data/expression_history.json` to reset deduplication

**5. Import Error: langgraph not found**
```
ModuleNotFoundError: No module named 'langgraph'
```
**Solution:** Run `pip install -r requirements.txt`

---

## ðŸŽ“ How It Works

### 1. Research Phase
- Generates optimized search queries using Ollama
- Searches arXiv (and optionally SSRN, Google Scholar) in parallel
- Extracts alpha ideas from paper abstracts using LLM

### 2. Idea Generation Phase
- Generates additional ideas using Ollama with context from historical performance
- Expands each idea into 3 variants (different time horizons, normalizations)

### 3. Formula Generation Phase
- Converts each idea into 2 WorldQuant Brain FASTEXPR formulas
- Uses Ollama to ensure valid syntax and proper operators
- Validates expressions (balanced parentheses, no look-ahead bias)

### 4. Deduplication
- Computes SHA256 fingerprints of normalized expressions
- Filters out duplicates to avoid wasting API quota

### 5. Simulation Phase
- Submits expressions to WorldQuant Brain API
- Polls for results (Sharpe, Fitness, Turnover, etc.)
- Stores results with metadata

### 6. Evaluation Phase
- **Hopeful:** Sharpe > 1.5 AND Fitness > 0.6 â†’ Save to production
- **Refine:** 0.5 < Sharpe < 1.5 â†’ Attempt refinement
- **Reject:** Sharpe < 0.5 â†’ Discard

### 7. Refinement Phase (if needed)
- **Negate:** If Sharpe < -0.5, flip signal direction
- **Adjust:** Use Ollama to modify parameters (windows, normalization, filters)
- Re-simulate refined expressions
- Max 2 refinement iterations per alpha

### 8. Iteration Control
- Continue until: 10+ hopeful alphas found OR max iterations reached
- Can start new research iteration or refine existing candidates

---

## ðŸš€ Advanced Usage

### Custom Prompts

Edit prompt templates in `prompts/`:
- `idea_generation.txt` - Control idea creativity and focus
- `formula_generation.txt` - Adjust expression complexity
- `paper_analysis.txt` - Change paper extraction logic
- `refinement.txt` - Modify refinement strategies

### Adding New Data Sources

To add SSRN or Google Scholar search:

1. Implement `_search_ssrn()` or `_search_google_scholar()` in `paper_research_agent.py`
2. Enable in config: `"sources": ["arxiv", "ssrn", "google_scholar"]`
3. May require additional libraries (e.g., `scholarly` for Google Scholar)

### Batch Processing Multiple Topics

```bash
# Create a batch script
for topic in momentum value quality volatility; do
  python main.py $topic --ideas 10 --iterations 3
done
```

---

## ðŸ“ˆ Performance Tips

1. **Increase parallelism**: Edit `max_papers_per_source` in config
2. **Reduce API calls**: Lower `ideas_per_cycle` and `expressions_per_idea`
3. **Focus research**: Use specific, targeted keywords
4. **Monitor quota**: WorldQuant Brain has daily simulation limits
5. **Enable deduplication**: Prevents retesting same alphas

---

## ðŸ¤ Contributing

This is a complete, production-ready system. To extend:

1. Add new agents in the same pattern as existing ones
2. Modify `alpha_workflow.py` to integrate new nodes
3. Update `graph_state.py` if new state fields needed
4. Create prompt templates for new LLM interactions

---

## ðŸ“„ License

MIT License - See consultant-agent project for details

---

## ðŸ™ Credits

- **LangGraph** - Workflow orchestration
- **Ollama** - LLM inference (gpt-oss:120b)
- **WorldQuant Brain** - Alpha simulation platform
- **arXiv** - Academic paper search API

---

## ðŸ“ž Support

For issues or questions:
1. Check logs in `logs/` directory
2. Review configuration in `config/langgraph_config.json`
3. Verify Ollama and WorldQuant credentials
4. Enable DEBUG logging: `python main.py <topic> --log-level DEBUG`

---

**Happy Alpha Hunting! ðŸŽ¯ðŸ“ˆ**
